{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up the notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import pandas and numpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Set some pandas options for controlling output\n",
    "pd.set_option('display.notebook_repr_html', False)\n",
    "pd.set_option('display.max_columns', 10)\n",
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading from CSV files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The sample CSV data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Open,High,Low,Close,Volume,Adj Close\r\n",
      "2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\r\n",
      "2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\r\n",
      "2014-07-17,84.35,84.63,83.33,83.63,1974000,83.63\r\n",
      "2014-07-16,83.77,84.91,83.66,84.91,1755600,84.91\r\n"
     ]
    }
   ],
   "source": [
    "# view the first five lines of data/msft.csv\n",
    "!head -n 5 data/msft.csv # mac or Linux\n",
    "# type data/msft.csv # on windows, but shows the entire file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading a CSV into a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3  2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4  2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in msft.csv into a DataFrame\n",
    "msft = pd.read_csv(\"data/msft.csv\")\n",
    "msft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying the index column when reading a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Open   High    Low  Close   Volume  Adj Close\n",
       "Date                                                      \n",
       "2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use column 0 as the index\n",
    "msft = pd.read_csv(\"data/msft.csv\", index_col=0)\n",
    "msft.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type inference and specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Open         float64\n",
       "High         float64\n",
       "Low          float64\n",
       "Close        float64\n",
       "Volume         int64\n",
       "Adj Close    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# examine the types of the columns in this DataFrame\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date          object\n",
       "Open         float64\n",
       "High         float64\n",
       "Low          float64\n",
       "Close        float64\n",
       "Volume       float64\n",
       "Adj Close    float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify that the Volume column should be a float64\n",
    "msft = pd.read_csv(\"data/msft.csv\", \n",
    "                   dtype = { 'Volume' : np.float64})\n",
    "msft.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Specifying column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             open   high    low  close   volume  adjclose\n",
       "2014-07-21  83.46  83.53  81.81  81.93  2359300     81.93\n",
       "2014-07-18  83.30  83.40  82.52  83.35  4020800     83.35\n",
       "2014-07-17  84.35  84.63  83.33  83.63  1974000     83.63\n",
       "2014-07-16  83.77  84.91  83.66  84.91  1755600     84.91\n",
       "2014-07-15  84.30  84.38  83.20  83.58  1874700     83.58"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# specify a new set of names for the columns\n",
    "# all lower case, remove space in Adj Close\n",
    "# also, header=0 skips the header row\n",
    "df = pd.read_csv(\"data/msft.csv\", \n",
    "                 header=0,\n",
    "                 names=['open', 'high', 'low', \n",
    "                        'close', 'volume', 'adjclose'])\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying specific columns to load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            Close\n",
       "Date             \n",
       "2014-07-21  81.93\n",
       "2014-07-18  83.35\n",
       "2014-07-17  83.63\n",
       "2014-07-16  84.91\n",
       "2014-07-15  83.58"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data only in the Date and Close columns\n",
    "# and index by the Date column\n",
    "df2 = pd.read_csv(\"data/msft.csv\", \n",
    "                  usecols=['Date', 'Close'], \n",
    "                  index_col=['Date'])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving a DataFrame to a CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save df2 to a new csv file\n",
    "# also specify naming the index as date\n",
    "df2.to_csv(\"data/msft_modified.csv\", index_label='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date,Close\r\n",
      "2014-07-21,81.93\r\n",
      "2014-07-18,83.35\r\n",
      "2014-07-17,83.63\r\n",
      "2014-07-16,84.91\r\n",
      "2014-07-15,83.58\r\n",
      "2014-07-14,84.4\r\n",
      "2014-07-11,83.35\r\n",
      "2014-07-10,83.42\r\n",
      "2014-07-09,85.5\r\n"
     ]
    }
   ],
   "source": [
    "# view the start of the file just saved\n",
    "!head data/msft_modified.csv\n",
    "#type data/msft_modified.csv # windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General field-delimited data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3  2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4  2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use read_table with sep=',' to read a CSV\n",
    "df = pd.read_table(\"data/msft.csv\", sep=',')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|Date|Open|High|Low|Close|Volume|Adj Close\r\n",
      "0|2014-07-21|83.46|83.53|81.81|81.93|2359300|81.93\r\n",
      "1|2014-07-18|83.3|83.4|82.52|83.35|4020800|83.35\r\n",
      "2|2014-07-17|84.35|84.63|83.33|83.63|1974000|83.63\r\n",
      "3|2014-07-16|83.77|84.91|83.66|84.91|1755600|84.91\r\n"
     ]
    }
   ],
   "source": [
    "# save as pipe delimited\n",
    "df.to_csv(\"data/msft_piped.txt\", sep='|')\n",
    "# check that it worked\n",
    "!head -n 5 data/msft_piped.txt # osx or Linux\n",
    "# type data/psft_piped.txt # on windows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handling variants of formats in field-delimited data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is fun because the data does not start on the first line\r\n",
      "Date,Open,High,Low,Close,Volume,Adj Close\r\n",
      "\r\n",
      "And there is space between the header row and data\r\n",
      "2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\r\n",
      "2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\r\n",
      "2014-07-17,84.35,84.63,83.33,83.63,1974000,83.63\r\n",
      "2014-07-16,83.77,84.91,83.66,84.91,1755600,84.91\r\n",
      "2014-07-15,84.30,84.38,83.20,83.58,1874700,83.58\r\n",
      "2014-07-14,83.66,84.64,83.11,84.40,1432100,84.40\r\n"
     ]
    }
   ],
   "source": [
    "# messy file\n",
    "!head data/msft2.csv # osx or Linux\n",
    "# type data/msft2.csv # windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3  2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4  2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58\n",
       "5  2014-07-14  83.66  84.64  83.11  84.40  1432100      84.40\n",
       "6  2014-07-11  83.55  83.98  82.85  83.35  2001400      83.35\n",
       "7  2014-07-10  85.20  85.57  83.36  83.42  2713300      83.42\n",
       "8  2014-07-09  84.83  85.79  84.76  85.50  1540700      85.50"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read, but skip rows 0, 2 and 3\n",
    "df = pd.read_csv(\"data/msft2.csv\", skiprows=[0, 2, 3])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date,Open,High,Low,Close,Volume,Adj Close\r\n",
      "2014-07-21,83.46,83.53,81.81,81.93,2359300,81.93\r\n",
      "2014-07-18,83.30,83.40,82.52,83.35,4020800,83.35\r\n",
      "\r\n",
      "Uh oh, there is stuff at the end."
     ]
    }
   ],
   "source": [
    "# another messy file, with the mess at the end\n",
    "!cat data/msft_with_footer.csv # osx or Linux\n",
    "# type data/msft_with_footer.csv # windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip only two lines at the end\n",
    "df = pd.read_csv(\"data/msft_with_footer.csv\", \n",
    "                 skip_footer=2,\n",
    "                 engine = 'python')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0  2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1  2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2  2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only process the first three rows\n",
    "pd.read_csv(\"data/msft.csv\", nrows=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             open   high    low  close      vol  adjclose\n",
       "2014-03-03  80.35  81.31  79.91  79.97  5004100     77.40\n",
       "2014-02-28  82.40  83.42  82.17  83.42  2853200     80.74\n",
       "2014-02-27  84.06  84.63  81.63  82.00  3676800     79.36\n",
       "2014-02-26  82.92  84.03  82.43  83.81  2623600     81.12\n",
       "2014-02-25  83.80  83.80  81.72  83.08  3579100     80.41"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# skip 100 lines, then only process the next five\n",
    "pd.read_csv(\"data/msft.csv\", skiprows=100, nrows=5, \n",
    "            header=0,\n",
    "            names=['open', 'high', 'low', 'close', 'vol', \n",
    "                   'adjclose'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing data in Excel format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close   Volume  Adj Close\n",
       "0 2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93\n",
       "1 2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35\n",
       "2 2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63\n",
       "3 2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91\n",
       "4 2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read excel file\n",
    "# only reads first sheet (msft in this case)\n",
    "df = pd.read_excel(\"data/stocks.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "        Date   Open   High    Low  Close    Volume  Adj Close\n",
       "0 2014-07-21  94.99  95.00  93.72  93.94  38887700      93.94\n",
       "1 2014-07-18  93.62  94.74  93.02  94.43  49898600      94.43\n",
       "2 2014-07-17  95.03  95.28  92.57  93.09  57152000      93.09\n",
       "3 2014-07-16  96.97  97.10  94.74  94.78  53396300      94.78\n",
       "4 2014-07-15  96.80  96.85  95.03  95.32  45477900      95.32"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from the aapl worksheet\n",
    "aapl = pd.read_excel(\"data/stocks.xlsx\", sheetname='aapl')\n",
    "aapl.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# save to an .XLS file, in worksheet 'Sheet1'\n",
    "df.to_excel(\"data/stocks2.xls\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write making the worksheet name MSFT\n",
    "df.to_excel(\"data/stocks_msft.xls\", sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write multiple sheets\n",
    "# requires use of the ExcelWriter class\n",
    "from pandas import ExcelWriter\n",
    "with ExcelWriter(\"data/all_stocks.xls\") as writer:\n",
    "    aapl.to_excel(writer, sheet_name='AAPL')\n",
    "    df.to_excel(writer, sheet_name='MSFT')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# write to xlsx\n",
    "df.to_excel(\"data/msft2.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing JSON files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"Date\":{\"0\":1405900800000,\"1\":1405641600000,\"2\":1405555200000,\"3\":1405468800000,\"4\":1405382400000},\"Open\":{\"0\":83.46,\"1\":83.3,\"2\":84.35,\"3\":83.77,\"4\":84.3},\"High\":{\"0\":83.53,\"1\":83.4,\"2\":84.63,\"3\":84.91,\"4\":84.38},\"Low\":{\"0\":81.81,\"1\":82.52,\"2\":83.33,\"3\":83.66,\"4\":83.2},\"Close\":{\"0\":81.93,\"1\":83.35,\"2\":83.63,\"3\":84.91,\"4\":83.58},\"Volume\":{\"0\":2359300,\"1\":4020800,\"2\":1974000,\"3\":1755600,\"4\":1874700},\"Adj Close\":{\"0\":81.93,\"1\":83.35,\"2\":83.63,\"3\":84.91,\"4\":83.58}}"
     ]
    }
   ],
   "source": [
    "# wirite the excel data to a JSON file\n",
    "df.head().to_json(\"data/stocks.json\")\n",
    "!cat data/stocks.json # osx or Linux\n",
    "#type data/stocks.json # windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   Adj Close  Close       Date   High    Low   Open   Volume\n",
       "0      81.93  81.93 2014-07-21  83.53  81.81  83.46  2359300\n",
       "1      83.35  83.35 2014-07-18  83.40  82.52  83.30  4020800\n",
       "2      83.63  83.63 2014-07-17  84.63  83.33  84.35  1974000\n",
       "3      84.91  84.91 2014-07-16  84.91  83.66  83.77  1755600\n",
       "4      83.58  83.58 2014-07-15  84.38  83.20  84.30  1874700"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data in from JSON\n",
    "df_from_json = pd.read_json(\"data/stocks.json\")\n",
    "df_from_json.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading HTML data from the Web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "html5lib not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-8b2d3dc847f9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"http://www.fdic.gov/bank/individual/failed/banklist.html\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# read it\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbanks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m# examine a subset of the first table read\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mbanks\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, tupleize_cols, thousands, encoding)\u001b[0m\n\u001b[1;32m    872\u001b[0m     \u001b[0m_validate_header_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m     return _parse(flavor, io, match, header, index_col, skiprows,\n\u001b[0;32m--> 874\u001b[0;31m                   parse_dates, tupleize_cols, thousands, attrs, encoding)\n\u001b[0m",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, header, index_col, skiprows, parse_dates, tupleize_cols, thousands, attrs, encoding)\u001b[0m\n\u001b[1;32m    724\u001b[0m     \u001b[0mretained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    725\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflavor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 726\u001b[0;31m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    727\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parser_dispatch\u001b[0;34m(flavor)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflavor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'bs4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html5lib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    669\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAS_HTML5LIB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 670\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"html5lib not found, please install it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    671\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAS_BS4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    672\u001b[0m             raise ImportError(\n",
      "\u001b[0;31mImportError\u001b[0m: html5lib not found, please install it"
     ]
    }
   ],
   "source": [
    "# the URL to read\n",
    "url = \"http://www.fdic.gov/bank/individual/failed/banklist.html\"\n",
    "# read it\n",
    "banks = pd.read_html(url)\n",
    "# examine a subset of the first table read\n",
    "banks[0][0:5].ix[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<table border=\"1\" class=\"dataframe\">\r\n",
      "  <thead>\r\n",
      "    <tr style=\"text-align: right;\">\r\n",
      "      <th></th>\r\n",
      "      <th>Date</th>\r\n",
      "      <th>Open</th>\r\n",
      "      <th>High</th>\r\n",
      "      <th>Low</th>\r\n",
      "      <th>Close</th>\r\n",
      "      <th>Volume</th>\r\n",
      "      <th>Adj Close</th>\r\n",
      "    </tr>\r\n",
      "  </thead>\r\n",
      "  <tbody>\r\n",
      "    <tr>\r\n",
      "      <th>0</th>\r\n",
      "      <td>2014-07-21</td>\r\n",
      "      <td>83.46</td>\r\n",
      "      <td>83.53</td>\r\n",
      "      <td>81.81</td>\r\n",
      "      <td>81.93</td>\r\n",
      "      <td>2359300</td>\r\n",
      "      <td>81.93</td>\r\n",
      "    </tr>\r\n",
      "    <tr>\r\n",
      "      <th>1</th>\r\n",
      "      <td>2014-07-18</td>\r\n",
      "      <td>83.30</td>\r\n"
     ]
    }
   ],
   "source": [
    "# read the stock data\n",
    "df = pd.read_excel(\"data/stocks.xlsx\")\n",
    "# write the first two rows to HTML\n",
    "df.head(2).to_html(\"data/stocks.html\")\n",
    "# check the first 28 lines of the output\n",
    "!head -n 28 data/stocks.html # max or Linux\n",
    "# type data/stocks.html # window, but prints the entire file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing HDF5 format files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'pandas.io.pytables.HDFStore'>\n",
       "File path: data/store.h5\n",
       "/df            frame        (shape->[8,3])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# seed for replication\n",
    "np.random.seed(123456)\n",
    "# create a DataFrame of dates and random numbers in three columns\n",
    "df = pd.DataFrame(np.random.randn(8, 3), \n",
    "                  index=pd.date_range('1/1/2000', periods=8),\n",
    "                  columns=['A', 'B', 'C'])\n",
    "\n",
    "# create HDF5 store\n",
    "store = pd.HDFStore('data/store.h5')\n",
    "store['df'] = df # persisting happened here\n",
    "store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   A         B         C\n",
       "2000-01-01  0.469112 -0.282863 -1.509059\n",
       "2000-01-02 -1.135632  1.212112 -0.173215\n",
       "2000-01-03  0.119209 -1.044236 -0.861849\n",
       "2000-01-04 -2.104569 -0.494929  1.071804\n",
       "2000-01-05  0.721555 -0.706771 -1.039575\n",
       "2000-01-06  0.271860 -0.424972  0.567020\n",
       "2000-01-07  0.276232 -1.087401 -0.673690\n",
       "2000-01-08  0.113648 -1.478427  0.524988"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data from HDF5\n",
    "store = pd.HDFStore(\"data/store.h5\")\n",
    "df = store['df']\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                   A         B         C\n",
       "2000-01-01  1.000000 -0.282863 -1.509059\n",
       "2000-01-02 -1.135632  1.212112 -0.173215"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# this changes the DataFrame, but did not persist\n",
    "df.ix[0].A = 1 \n",
    "\n",
    "# to persist the change, assign the DataFrame to the \n",
    "# HDF5 store object\n",
    "store['df'] = df\n",
    "# it is now persisted\n",
    "\n",
    "# the following loads the store and \n",
    "# shows the first two rows, demonstrating\n",
    "# the the persisting was done\n",
    "pd.HDFStore(\"data/store.h5\")['df'].head(2) # it's now in there"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing data on the web and in the cloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Date       Open       High        Low      Close    Volume  Adj Close\n",
       "0  2014-06-30  42.169998  42.209999  41.700001  41.700001  30793100  39.019329\n",
       "1  2014-06-27  41.610001  42.290001  41.509998  42.250000  74640000  39.533972\n",
       "2  2014-06-26  41.930000  41.939999  41.430000  41.720001  23604400  39.038044\n",
       "3  2014-06-25  41.700001  42.049999  41.459999  42.029999  20049100  39.328114\n",
       "4  2014-06-24  41.830002  41.939999  41.560001  41.750000  26509100  39.066115"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read csv directly from Yahoo! Finance from a URL\n",
    "df = pd.read_csv(\"http://ichart.yahoo.com/table.csv?s=MSFT&\" +\n",
    "                 \"a=5&b=1&c=2014&\" +\n",
    "                 \"d=5&e=30&f=2014&\" +\n",
    "                 \"g=d&ignore=.csv\")\n",
    "df[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading and writing from/to SQL databases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelheydt/anaconda/lib/python3.5/site-packages/pandas/core/generic.py:1165: UserWarning: The spaces in these column names will not be changed. In pandas versions < 0.14, spaces were converted to underscores.\n",
      "  chunksize=chunksize, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "# reference SQLite\n",
    "import sqlite3\n",
    "\n",
    "# read in the stock data from CSV\n",
    "msft = pd.read_csv(\"data/msft.csv\")\n",
    "msft[\"Symbol\"]=\"MSFT\"\n",
    "aapl = pd.read_csv(\"data/aapl.csv\")\n",
    "aapl[\"Symbol\"]=\"AAPL\"\n",
    "\n",
    "# create connection\n",
    "connection = sqlite3.connect(\"data/stocks.sqlite\")\n",
    "# .to_sql() will create SQL to store the DataFrame\n",
    "# in the specified table.  if_exists specifies\n",
    "# what to do if the table already exists\n",
    "msft.to_sql(\"STOCK_DATA\", connection, if_exists=\"replace\")\n",
    "aapl.to_sql(\"STOCK_DATA\", connection, if_exists=\"append\")\n",
    "\n",
    "# commit the SQL and close the connection\n",
    "connection.commit()\n",
    "connection.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Date   Open   High    Low  Close   Volume  Adj Close Symbol\n",
       "index                                                                   \n",
       "0      2014-07-21  83.46  83.53  81.81  81.93  2359300      81.93   MSFT\n",
       "1      2014-07-18  83.30  83.40  82.52  83.35  4020800      83.35   MSFT\n",
       "2      2014-07-17  84.35  84.63  83.33  83.63  1974000      83.63   MSFT\n",
       "3      2014-07-16  83.77  84.91  83.66  84.91  1755600      84.91   MSFT\n",
       "4      2014-07-15  84.30  84.38  83.20  83.58  1874700      83.58   MSFT"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# connect to the database file\n",
    "connection = sqlite3.connect(\"data/stocks.sqlite\")\n",
    "\n",
    "# query all records in STOCK_DATA\n",
    "# returns a DataFrame\n",
    "# inde_col specifies which column to make the DataFrame index\n",
    "stocks = pd.io.sql.read_sql(\"SELECT * FROM STOCK_DATA;\", \n",
    "                             connection, index_col='index')\n",
    "\n",
    "# close the connection\n",
    "connection.close()\n",
    "\n",
    "# report the head of the data retrieved\n",
    "stocks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Date   Open   High    Low  Close    Volume  Adj Close Symbol\n",
       "index                                                                    \n",
       "1081   2010-05-21  42.22  42.35  40.99  42.00  33610800      36.48   MSFT\n",
       "1097   2010-04-29  46.80  46.95  44.65  45.92  47076200      38.41   MSFT\n",
       "1826   2007-06-15  89.80  92.10  89.55  92.04  30656400      35.87   MSFT\n",
       "3455   2001-03-16  47.00  47.80  46.10  45.33  40806400      17.66   MSFT\n",
       "3712   2000-03-17  49.50  50.00  48.29  50.00  50860500      19.48   MSFT"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# open the connection\n",
    "connection = sqlite3.connect(\"data/stocks.sqlite\")\n",
    "\n",
    "# construct the query string\n",
    "query = \"SELECT * FROM STOCK_DATA WHERE Volume>29200100 AND Symbol='MSFT';\"\n",
    "\n",
    "# execute and close connection\n",
    "items = pd.io.sql.read_sql(query, connection, index_col='index')\n",
    "connection.close()\n",
    "\n",
    "# report the query result\n",
    "items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data from remote data services"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading stock data from Yahoo! and Google Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/michaelheydt/anaconda/lib/python3.5/site-packages/pandas/io/data.py:35: FutureWarning: \n",
      "The pandas.io.data module is moved to a separate package (pandas-datareader) and will be removed from pandas in a future version.\n",
      "After installing the pandas-datareader package (https://github.com/pydata/pandas-datareader), you can change the import ``from pandas.io import data, wb`` to ``from pandas_datareader import data, wb``.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                 Open       High        Low      Close    Volume  Adj Close\n",
       "Date                                                                       \n",
       "2012-01-03  26.549999  26.959999  26.389999  26.770000  64731500  23.304317\n",
       "2012-01-04  26.820000  27.469999  26.780001  27.400000  80516100  23.852755\n",
       "2012-01-05  27.379999  27.730000  27.290001  27.680000  56081400  24.096507\n",
       "2012-01-06  27.530001  28.190001  27.530001  28.110001  99455500  24.470839\n",
       "2012-01-09  28.049999  28.100000  27.719999  27.740000  59706800  24.148739"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# import pandas.io.data namespace, alias as web\n",
    "import pandas.io.data as web\n",
    "# and datetime for the dates\n",
    "import datetime\n",
    "\n",
    "# start end end dates\n",
    "start = datetime.datetime(2012, 1, 1)\n",
    "end = datetime.datetime(2014, 1, 27)\n",
    "\n",
    "# read the MSFT stock data from yahoo! and view the head\n",
    "yahoo = web.DataReader('MSFT', 'yahoo', start, end)\n",
    "yahoo.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "             Open   High    Low  Close    Volume\n",
       "Date                                            \n",
       "2012-01-03  26.55  26.96  26.39  26.76  64735391\n",
       "2012-01-04  26.82  27.47  26.78  27.40  80519402\n",
       "2012-01-05  27.38  27.73  27.29  27.68  56082205\n",
       "2012-01-06  27.53  28.19  27.52  28.10  99459469\n",
       "2012-01-09  28.05  28.10  27.72  27.74  59708266"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from google and display the head of the data\n",
    "goog = web.DataReader(\"MSFT\", 'google', start, end)\n",
    "goog.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieving options data from Yahoo! Finance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "RemoteDataError",
     "evalue": "Data not available",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/site-packages/pandas/io/data.py\u001b[0m in \u001b[0;36mexpiry_dates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1162\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m             \u001b[0mexpiry_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expiry_dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Options' object has no attribute '_expiry_dates'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRemoteDataError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-bab4b6c5d2e9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m#data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0maapl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0maapl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_all_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/site-packages/pandas/io/data.py\u001b[0m in \u001b[0;36mget_all_data\u001b[0;34m(self, call, put)\u001b[0m\n\u001b[1;32m   1132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m             \u001b[0mexpiry_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpiry_dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m             \u001b[0mexpiry_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_expiry_dates_and_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/site-packages/pandas/io/data.py\u001b[0m in \u001b[0;36mexpiry_dates\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1163\u001b[0m             \u001b[0mexpiry_dates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_expiry_dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0mexpiry_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_expiry_dates_and_links\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mexpiry_dates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1167\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/site-packages/pandas/io/data.py\u001b[0m in \u001b[0;36m_get_expiry_dates_and_links\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1190\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpiry_dates\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1191\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRemoteDataError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Data not available'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1193\u001b[0m         \u001b[0mexpiry_links\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpiry_dates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRemoteDataError\u001b[0m: Data not available"
     ]
    }
   ],
   "source": [
    "# specify we want all yahoo options data for AAPL\n",
    "# this can take a little time...\n",
    "aapl = pd.io.data.Options('AAPL', 'yahoo')\n",
    "# read all the data\n",
    "#data = aapl.get_all_data()\n",
    "# examine the first six rows and four columns\n",
    "#data.iloc[0:6, 0:4]\n",
    "#data\n",
    "aapl\n",
    "aapl.get_all_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get all puts at strike price of $80 (first four columns only)\n",
    "data.loc[(80, slice(None), 'put'), :].iloc[0:5, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# put options at strike of $80, between 2015-01-17 and 2015-04-17\n",
    "data.loc[(80, slice('20150117','20150417'), \n",
    "          'put'), :].iloc[:, 0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# msft calls expiring on 2015-01-05\n",
    "expiry = datetime.date(2015, 1, 5)\n",
    "msft_calls = pd.io.data.Options('MSFT', 'yahoo').get_call_data(\n",
    "                                                    expiry=expiry)\n",
    "msft_calls.iloc[0:5, 0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# msft calls expiring on 2015-01-05\n",
    "expiry = datetime.date(2015, 1, 17)\n",
    "aapl_calls = aapl.get_call_data(expiry=expiry)\n",
    "aapl_calls.iloc[0:5, 0:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading economic data from the Federal Reserve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "                GDP\n",
       "DATE               \n",
       "2012-01-01  15973.9\n",
       "2012-04-01  16121.9\n",
       "2012-07-01  16227.9\n",
       "2012-10-01  16297.3\n",
       "2013-01-01  16475.4\n",
       "2013-04-01  16541.4\n",
       "2013-07-01  16749.3\n",
       "2013-10-01  16999.9\n",
       "2014-01-01  17025.2"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read GDP data from FRED\n",
    "gdp = web.DataReader(\"GDP\", \"fred\", \n",
    "                     datetime.date(2012, 1, 1), \n",
    "                     datetime.date(2014, 1, 27))\n",
    "gdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "            A576RC1A027NBEA\n",
       "DATE                       \n",
       "1929-01-01             50.5\n",
       "1930-01-01             46.2\n",
       "1931-01-01             39.2\n",
       "1932-01-01             30.5\n",
       "1933-01-01             29.0\n",
       "...                     ...\n",
       "2009-01-01           6251.4\n",
       "2010-01-01           6377.5\n",
       "2011-01-01           6633.2\n",
       "2012-01-01           6930.3\n",
       "2013-01-01           7114.4\n",
       "\n",
       "[85 rows x 1 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get Compensation of employees: Wages and salaries\n",
    "web.DataReader(\"A576RC1A027NBEA\",\n",
    "               \"fred\", \n",
    "               datetime.date(1929, 1, 1),\n",
    "               datetime.date(2013, 1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Kenneth French data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3:         1 b'Mkt-RF'  2 b'SMB'  3 b'HML'  4 b'WML'  5 b'RF'\n",
       " 199007         0.79      0.07      0.24    -99.99     0.68\n",
       " 199008       -10.76     -1.56      0.42    -99.99     0.66\n",
       " 199009       -12.24      1.68      0.34    -99.99     0.60\n",
       " 199010         9.58     -8.11     -3.29    -99.99     0.68\n",
       " 199011        -3.87      1.62      0.68     -0.32     0.57\n",
       " ...             ...       ...       ...       ...      ...\n",
       " 201509        -3.91     -0.28     -0.89      3.47     0.00\n",
       " 201510         7.30     -2.26      0.21     -2.62     0.00\n",
       " 201511        -0.30      1.69     -1.78      2.11     0.00\n",
       " 201512        -1.74      0.93     -1.79      3.28     0.01\n",
       " 201601        -6.29     -2.10      0.97      0.51     0.01\n",
       " \n",
       " [307 rows x 5 columns]}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read from Kenneth French fama global factors data set\n",
    "factors = web.DataReader(\"Global_Factors\", \"famafrench\")\n",
    "factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading from the World Bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "HTTPError",
     "evalue": "HTTP Error 502: Bad Gateway",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-7828a6335f11>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwb\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# get all indicators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mall_indicators\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_indicators\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/site-packages/pandas/io/wb.py\u001b[0m in \u001b[0;36mget_indicators\u001b[0;34m()\u001b[0m\n\u001b[1;32m    247\u001b[0m     \"\"\"\n\u001b[1;32m    248\u001b[0m     \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'http://api.worldbank.org/indicators?per_page=50000&format=json'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    161\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    470\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_response\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 472\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mhttp_response\u001b[0;34m(self, request, response)\u001b[0m\n\u001b[1;32m    580\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m200\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mcode\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    581\u001b[0m             response = self.parent.error(\n\u001b[0;32m--> 582\u001b[0;31m                 'http', request, response, code, msg, hdrs)\n\u001b[0m\u001b[1;32m    583\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36merror\u001b[0;34m(self, proto, *args)\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhttp_err\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m             \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'default'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'http_error_default'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0morig_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_chain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[0;31m# XXX probably also want an abstract factory that knows when it makes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36m_call_chain\u001b[0;34m(self, chain, kind, meth_name, *args)\u001b[0m\n\u001b[1;32m    442\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhandler\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhandlers\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m             \u001b[0mfunc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandler\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    445\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/michaelheydt/anaconda/lib/python3.5/urllib/request.py\u001b[0m in \u001b[0;36mhttp_error_default\u001b[0;34m(self, req, fp, code, msg, hdrs)\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPDefaultErrorHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mhttp_error_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull_url\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhdrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mHTTPRedirectHandler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseHandler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mHTTPError\u001b[0m: HTTP Error 502: Bad Gateway"
     ]
    }
   ],
   "source": [
    "# make referencing pandas.io.wb a little less typing\n",
    "import pandas.io.wb as wb\n",
    "# get all indicators\n",
    "all_indicators = wb.get_indicators()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_indicators' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-3044034b80af>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# examine some of the indicators\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_indicators\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'all_indicators' is not defined"
     ]
    }
   ],
   "source": [
    "# examine some of the indicators\n",
    "all_indicators.ix[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# search of life expectancy indicators\n",
    "le_indicators = wb.search(\"life expectancy\")\n",
    "# report first three rows, first two columns\n",
    "le_indicators.iloc[:3,:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get countries and show the 3 digit code and name\n",
    "countries = wb.get_countries()\n",
    "# show a subset of the country data\n",
    "countries.iloc[0:10].ix[:,['name', 'capitalCity', 'iso2c']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get life expectancy at birth for all countries from 1980 to 2014\n",
    "le_data_all = wb.download(indicator=\"SP.DYN.LE00.IN\", \n",
    "                          start='1980', \n",
    "                          end='2014')\n",
    "le_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# only US, CAN, and MEX are returned by default\n",
    "le_data_all.index.levels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'countries' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-53-ebbe15aefefb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# from 1980 to 2014\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m le_data_all = wb.download(indicator=\"SP.DYN.LE00.IN\", \n\u001b[0;32m----> 4\u001b[0;31m                           \u001b[0mcountry\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcountries\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'iso2c'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m                           \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'1980'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                           end='2012')\n",
      "\u001b[0;31mNameError\u001b[0m: name 'countries' is not defined"
     ]
    }
   ],
   "source": [
    "# retrieve life expectancy at birth for all countries \n",
    "# from 1980 to 2014\n",
    "le_data_all = wb.download(indicator=\"SP.DYN.LE00.IN\", \n",
    "                          country = countries['iso2c'],\n",
    "                          start='1980', \n",
    "                          end='2012')\n",
    "le_data_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'le_data_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-54-5cb915f9a262>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#le_data_all.pivot(index='country', columns='year')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m le_data = le_data_all.reset_index().pivot(index='country', \n\u001b[0m\u001b[1;32m      3\u001b[0m                                           columns='year')\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# examine pivoted data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mle_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'le_data_all' is not defined"
     ]
    }
   ],
   "source": [
    "#le_data_all.pivot(index='country', columns='year')\n",
    "le_data = le_data_all.reset_index().pivot(index='country', \n",
    "                                          columns='year')\n",
    "# examine pivoted data\n",
    "le_data.ix[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'le_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-653e5c5775a3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ask what is the name of country for each year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# with the least life expectancy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mcountry_with_least_expectancy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0midxmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mcountry_with_least_expectancy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'le_data' is not defined"
     ]
    }
   ],
   "source": [
    "# ask what is the name of country for each year\n",
    "# with the least life expectancy\n",
    "country_with_least_expectancy = le_data.idxmin(axis=0)\n",
    "country_with_least_expectancy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'le_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-56-fb29e8bee14c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# and what is the minimum life expectancy for each year\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mexpectancy_for_least_country\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mle_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mexpectancy_for_least_country\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'le_data' is not defined"
     ]
    }
   ],
   "source": [
    "# and what is the minimum life expectancy for each year\n",
    "expectancy_for_least_country = le_data.min(axis=0)\n",
    "expectancy_for_least_country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'country_with_least_expectancy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-6c91fa6f4c27>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# year, country and expectancy where there minimum exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m least = pd.DataFrame(\n\u001b[0;32m----> 4\u001b[0;31m     data = {'Country': country_with_least_expectancy.values,\n\u001b[0m\u001b[1;32m      5\u001b[0m             'Expectancy': expectancy_for_least_country.values},\n\u001b[1;32m      6\u001b[0m     index = country_with_least_expectancy.index.levels[1])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'country_with_least_expectancy' is not defined"
     ]
    }
   ],
   "source": [
    "# this merges the two frames together and gives us\n",
    "# year, country and expectancy where there minimum exists\n",
    "least = pd.DataFrame(\n",
    "    data = {'Country': country_with_least_expectancy.values,\n",
    "            'Expectancy': expectancy_for_least_country.values},\n",
    "    index = country_with_least_expectancy.index.levels[1])\n",
    "least"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
